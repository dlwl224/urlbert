# /home/kong/urlbert/url_bert/urlbert2/core/url_analyzer.py

import os
import sys

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ (core)
current_dir = os.path.dirname(os.path.abspath(__file__))
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (urlbert2)
project_root = os.path.abspath(os.path.join(current_dir, '..'))

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²€ìƒ‰ ê²½ë¡œì— ì¶”ê°€
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import torch
import torch.nn.functional as F
import requests
import random
import numpy as np

from pytorch_pretrained_bert import BertTokenizer 
from lime.lime_text import LimeTextExplainer

from config import (
    PAD_SIZE, DEVICE, CLASS_LABELS, IMPORTANT_HEADERS,
    REQUEST_TIMEOUT_SECONDS, LIME_NUM_FEATURES, LIME_NUM_SAMPLES,
    TRUSTED_DOMAINS_FOR_EXPLANATION
)

# --- HTTP í—¤ë” ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜ ---
def get_header_info(url: str) -> str:
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/114 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 Version/14.0.3 Safari/605.1.15",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 Version/14.0 Mobile/15E148 Safari/604.1"
    ]
    headers = {
        "User-Agent": random.choice(user_agents),
        "Accept-Language": "en-US,en;q=0.9",
        "Referer": "https://www.google.com/"
    }

    try:
        response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT_SECONDS, allow_redirects=True)
        resp_headers = response.headers
        
        # IMPORTANT_HEADERSê°€ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜ë˜ì–´ ìˆë‹¤ë©´
        important = {
            k: resp_headers.get(k, "") for k in IMPORTANT_HEADERS
        } 
        header_str = ", ".join(f"{k}: {v}" for k, v in important.items() if v)
        return header_str if header_str else "NOHEADER"
    except requests.exceptions.RequestException:
        return "NOHEADER"
    except Exception:
        return "NOHEADER"

# --- ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜  ---
def preprocess_url_for_inference(url: str, header_info: str, tokenizer: BertTokenizer, pad_size: int = PAD_SIZE):
    text = f"{url} [SEP] {header_info}"
    tokenized_text = tokenizer.tokenize(text)
    
    tokens = ["[CLS]"] + tokenized_text + ["[SEP]"]
    ids = tokenizer.convert_tokens_to_ids(tokens)
    types = [0] * (len(ids)) 
    masks = [1] * len(ids)

    if len(ids) < pad_size:
        types = types + [1] * (pad_size - len(ids)) 
        masks = masks + [0] * (pad_size - len(ids))
        ids = ids + [0] * (pad_size - len(ids))
    else:
        types = types[:pad_size]
        masks = masks[:pad_size]
        ids = ids[:pad_size]

    assert len(ids) == len(masks) == len(types) == pad_size

    return (
        torch.tensor([ids], dtype=torch.long).to(DEVICE),
        torch.tensor([types], dtype=torch.long).to(DEVICE),
        torch.tensor([masks], dtype=torch.long).to(DEVICE)
    )

# --- LIME ì„¤ëª…ìë¥¼ ìœ„í•œ ì˜ˆì¸¡ í•¨ìˆ˜  ---
def lime_predictor_fn(texts, model, tokenizer): 
    probabilities = []
    for text_input in texts:
        parts = text_input.split(" [SEP] ", 1)
        url_part = parts[0]
        header_part = parts[1] if len(parts) > 1 else "NOHEADER"

        input_ids, input_types, input_masks = preprocess_url_for_inference(
            url_part, header_part, tokenizer, PAD_SIZE
        )

        with torch.no_grad():
            outputs = model([input_ids, input_types, input_masks])
            probs = F.softmax(outputs, dim=1).cpu().numpy()
            probabilities.append(probs[0])
    return np.array(probabilities)

# --- URL ë¶„ë¥˜ ë° ì„¤ëª… ìƒì„± í•¨ìˆ˜ ---
def classify_url_with_explanation(url: str, model, tokenizer) -> dict: 
    print(f"\nURL ë¶„ì„ ì‹œì‘: {url}")
    header_info = get_header_info(url)
    print(f"ì¶”ì¶œëœ í—¤ë” ì •ë³´: {header_info if header_info != 'NOHEADER' else 'ì—†ìŒ'}")

    input_ids, input_types, input_masks = preprocess_url_for_inference(
        url, header_info, tokenizer, PAD_SIZE
    )

    with torch.no_grad():
        outputs = model([input_ids, input_types, input_masks])
        probabilities = F.softmax(outputs, dim=1)
        predicted_class_id = torch.argmax(probabilities, dim=1).item()

    predicted_label = CLASS_LABELS[predicted_class_id]
    confidence = probabilities[0][predicted_class_id].item() * 100

    full_text_for_lime = f"{url} [SEP] {header_info}"

    try:
        explainer = LimeTextExplainer(class_names=list(CLASS_LABELS.values()))

        explanation = explainer.explain_instance(
            full_text_for_lime,
            classifier_fn=lambda texts: lime_predictor_fn(texts, model, tokenizer),
            labels=[0, 1], 
            num_features=LIME_NUM_FEATURES, 
            num_samples=LIME_NUM_SAMPLES 
        )

        explanation_list = explanation.as_list(label=predicted_class_id)
        
        # --- LIME ì„¤ëª… ìš”ì•½ ë¡œì§ ê°œì„  ---
        reason_phrases = []
        
        # ì´í•´í•˜ê¸° ì‰¬ìš´ í‚¤ì›Œë“œë¥¼ í•„í„°ë§í•˜ê³  ì„¤ëª… ë¬¸êµ¬ë¥¼ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
        # ë°˜í™˜ê°’ì€ (ì„¤ëª… ë¬¸êµ¬, í•´ë‹¹ íŠ¹ì§•ì˜ ì¼ë°˜ì ì¸ ì˜ë¯¸ ì„¤ëª…) íŠœí”Œ
        def get_understandable_explanation_text_and_meaning(word, weight, current_predicted_label): # predicted_label_context_for_meaning ë§¤ê°œë³€ìˆ˜ ì œê±°
            # 1ë‹¨ê³„ í•„í„°ë§: BERT íŠ¹ìˆ˜ í† í°, ë„ˆë¬´ ê¸´ ë¬¸ìì—´, ë¶ˆí•„ìš”í•œ ì¿ í‚¤/ì„¸ì…˜ ì´ë¦„
            if word.strip().lower() in ["[sep]", "[cls]", "[pad]", "sep", "cls", "pad"] or \
               len(word) > 50 or \
               word.upper() in ["NID", "SID", "PHPSESSID", "AEC"]:
                return None, None
            
            # 2ë‹¨ê³„: ê¸°ì—¬ë„ì— ë”°ë¥¸ ì„¤ëª… ë¬¸êµ¬ì™€ ì˜ë¯¸ ìƒì„±
            display_text = ""
            meaning = ""
            
            # 'benign' ì˜ˆì¸¡ ì‹œ, ì–‘ìˆ˜ ê¸°ì—¬ë„ëŠ” 'ì •ìƒìœ¼ë¡œ ë§Œë“œëŠ” ìš”ì¸', ìŒìˆ˜ ê¸°ì—¬ë„ëŠ” 'ì•…ì„±ìœ¼ë¡œ ë¯¸ëŠ” ìš”ì¸'
            # 'malicious' ì˜ˆì¸¡ ì‹œ, ì–‘ìˆ˜ ê¸°ì—¬ë„ëŠ” 'ì•…ì„±ìœ¼ë¡œ ë§Œë“œëŠ” ìš”ì¸', ìŒìˆ˜ ê¸°ì—¬ë„ëŠ” 'ì •ìƒìœ¼ë¡œ ë¯¸ëŠ” ìš”ì¸'
            
            # --- ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë„ë©”ì¸ ---
            if word.lower() in TRUSTED_DOMAINS_FOR_EXPLANATION:
                meaning = "ì›¹ì‚¬ì´íŠ¸ì˜ ì£¼ì†Œ(ë„ë©”ì¸)ëŠ” í•´ë‹¹ ì›¹ì‚¬ì´íŠ¸ì˜ ì‹ ë¢°ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. ë„ë¦¬ ì•Œë ¤ì§€ê³  ì•ˆì „í•˜ê²Œ ì‚¬ìš©ë˜ëŠ” ë„ë©”ì¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ì•ˆì „í•œ URLë¡œ íŒë‹¨ë  ê°€ëŠ¥ì„±ì„ ë†’ì…ë‹ˆë‹¤."
                if current_predicted_label == 'benign' and weight > 0:
                    display_text = f"'{word}'ì™€ ê°™ì€ **ë„ë¦¬ ì•Œë ¤ì§€ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë„ë©”ì¸**ì´ ì´ URLì„ ì •ìƒìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë° ê¸ì •ì ì¸ ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'malicious' and weight < 0: # ì•…ì„±ìœ¼ë¡œ íŒë‹¨ë˜ì—ˆì§€ë§Œ, ì´ ë„ë©”ì¸ì€ ì•…ì„±ìœ¼ë¡œ ê°€ëŠ” ê²ƒì„ ë§‰ëŠ” ë° ê¸°ì—¬ (ì¦‰, ì •ìƒìœ¼ë¡œ ë¯¸ëŠ” ìš”ì†Œ)
                    display_text = f"'{word}'ì™€ ê°™ì€ **ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë„ë©”ì¸**ì€ ì´ URLì´ ì•…ì„±ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ì™„í™”í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì•…ì„± URLì´ ì •ìƒ ì‚¬ì´íŠ¸ë¥¼ ëª¨ë°©í•˜ë ¤ í•  ë•Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆëŠ” íŒ¨í„´ì…ë‹ˆë‹¤."
                else: # ì‹ ë¢° ë„ë©”ì¸ì´ì§€ë§Œ ì˜ˆì¸¡ê³¼ ë°˜ëŒ€ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ ê¸°ì—¬ (ì˜ˆ: ì •ìƒì¸ë° ìŒìˆ˜ ê¸°ì—¬) -> ì¶œë ¥í•˜ì§€ ì•ŠìŒ
                    return None, None
            
            # --- HTTPS/HTTP ---
            elif word.lower() == 'https':
                meaning = "HTTPSëŠ” ì›¹ì‚¬ì´íŠ¸ì™€ ì‚¬ìš©ì ê°„ì˜ í†µì‹ ì„ ì•”í˜¸í™”í•˜ì—¬ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë³´í˜¸í•˜ëŠ” í”„ë¡œí† ì½œì…ë‹ˆë‹¤. HTTPS ì‚¬ìš©ì€ URLì˜ ë³´ì•ˆ ìˆ˜ì¤€ì„ ë†’ì´ëŠ” ê¸ì •ì ì¸ ì‹ í˜¸ì…ë‹ˆë‹¤."
                if current_predicted_label == 'benign' and weight > 0:
                    display_text = f"ì•ˆì „í•œ **HTTPS ì—°ê²°**ì´ ì´ URLì„ ì •ìƒìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë° ê¸ì •ì ì¸ ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'malicious' and weight < 0:
                    display_text = f"ì•ˆì „í•œ **HTTPS ì—°ê²°**ì€ ì´ URLì´ ì•…ì„±ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ì™„í™”í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤."
                else:
                    display_text = f"ì•ˆì „í•œ **HTTPS ì—°ê²°**ì´ ì´ URL íŒë‹¨ì— {('ê¸ì •ì ì¸' if weight > 0 else 'ë¶€ì •ì ì¸')} ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
            elif word.lower() == 'http':
                meaning = "HTTPëŠ” ì•”í˜¸í™”ë˜ì§€ ì•Šì€ í†µì‹  í”„ë¡œí† ì½œë¡œ, ë°ì´í„°ê°€ ë…¸ì¶œë  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ìµœì‹  ì›¹ì‚¬ì´íŠ¸ëŠ” ëŒ€ë¶€ë¶„ HTTPSë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, HTTPë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ìš”ì†Œë¡œ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                if current_predicted_label == 'malicious' and weight > 0:
                    display_text = f"ë³´ì•ˆì— ì·¨ì•½í•œ 'HTTP' í”„ë¡œí† ì½œì´ ì´ URLì„ ì•…ì„±ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë° ê¸ì •ì ì¸ ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'benign' and weight < 0:
                    display_text = f"ë³´ì•ˆì— ì·¨ì•½í•œ 'HTTP' í”„ë¡œí† ì½œì€ ì´ URLì´ ì •ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ë°©í•´í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤."
                else:
                    display_text = f"ë³´ì•ˆì— ì·¨ì•½í•œ 'HTTP' í”„ë¡œí† ì½œì´ ì´ URL íŒë‹¨ì— {('ê¸ì •ì ì¸' if weight > 0 else 'ë¶€ì •ì ì¸')} ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."

            # --- WWW ---
            elif word.lower() == 'www':
                meaning = "ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ì ì¸ ì›¹ì‚¬ì´íŠ¸ëŠ” 'www' ì ‘ë‘ì‚¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŠ” í‘œì¤€ì ì¸ ì›¹ ì£¼ì†Œ í˜•íƒœë¡œ, URLì˜ ì •ìƒì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì‹ í˜¸ë¡œ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                if current_predicted_label == 'benign' and weight > 0:
                    display_text = f"'WWW' ì ‘ë‘ì‚¬ ì‚¬ìš©ì´ ì´ URLì„ ì •ìƒìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë° ê¸ì •ì ì¸ ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'malicious' and weight < 0:
                    display_text = f"'WWW' ì ‘ë‘ì‚¬ ì‚¬ìš©ì€ ì´ URLì´ ì•…ì„±ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ì™„í™”í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤."
                else:
                    display_text = f"'WWW' ì ‘ë‘ì‚¬ ì‚¬ìš©ì´ ì´ URL íŒë‹¨ì— {('ê¸ì •ì ì¸' if weight > 0 else 'ë¶€ì •ì ì¸')} ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
            
            # --- NOHEADER --- 
            elif word.lower() == 'noheader':
                meaning = "URL ì ‘ì† ì‹œ **HTTP í—¤ë” ì •ë³´ê°€ ì „í˜€ ì—†ê±°ë‚˜ ë¹„ì •ìƒì ì¸ ê²½ìš°**, ì´ëŠ” ì„œë²„ ì„¤ì •ì˜ ë¬¸ì œì´ê±°ë‚˜, ì •ë³´ë¥¼ ìˆ¨ê²¨ ë¶„ì„ì„ ì–´ë µê²Œ í•˜ë ¤ëŠ” ì•…ì˜ì ì¸ ì‹œë„ë¡œ í•´ì„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •ìƒì ì¸ ì›¹ì‚¬ì´íŠ¸ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ì–‘í•œ í—¤ë” ì •ë³´ë¥¼ ì£¼ê³ ë°›ìŠµë‹ˆë‹¤."
                if current_predicted_label == 'malicious' and weight > 0:
                    display_text = f"**HTTP í—¤ë” ì •ë³´ ë¶€ì¬**ê°€ ì´ URLì„ ì•…ì„±ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë° ê¸ì •ì ì¸ ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'benign' and weight < 0:
                    display_text = f"**HTTP í—¤ë” ì •ë³´ ë¶€ì¬**ëŠ” ì´ URLì´ ì •ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ë°©í•´í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤."
                else:
                    display_text = f"**HTTP í—¤ë” ì •ë³´ ë¶€ì¬**ê°€ ì´ URL íŒë‹¨ì— {('ê¸ì •ì ì¸' if weight > 0 else 'ë¶€ì •ì ì¸')} ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
            
            # --- ì¤‘ìš” HTTP í—¤ë” ì´ë¦„ --- 
            elif word in IMPORTANT_HEADERS: 
                meaning = f"'{word}' í—¤ë”ëŠ” ì›¹ ì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ ê°„ì˜ í†µì‹  ì •ë³´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì´ í—¤ë”ì˜ ë‚´ìš©ì´ë‚˜ ì¡´ì¬ ì—¬ë¶€ëŠ” ì›¹ì‚¬ì´íŠ¸ì˜ íŠ¹ì„±(ì˜ˆ: ì‚¬ìš©ëœ ì›¹ ì„œë²„ ì¢…ë¥˜, ì½˜í…ì¸  íƒ€ì…, ì¿ í‚¤ ì„¤ì • ë“±)ì„ íŒŒì•…í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. ì•…ì„± ì‚¬ì´íŠ¸ì˜ ê²½ìš° ì •ìƒì ì¸ í—¤ë”ê°€ ì—†ê±°ë‚˜, í”¼ì‹±ì„ ìœ„í•´ íŠ¹ì • í—¤ë”ë¥¼ ì¡°ì‘í•˜ëŠ” ë“± ë¹„ì •ìƒì ì¸ ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                if current_predicted_label == 'malicious' and weight > 0:
                    display_text = f"'{word}' í—¤ë”ì˜ íŠ¹ì • ê°’ì´ ì´ URLì„ ì•…ì„±ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë° ê¸ì •ì ì¸ ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'benign' and weight < 0:
                    display_text = f"'{word}' í—¤ë”ì˜ íŠ¹ì • ê°’ì€ ì´ URLì´ ì •ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ë°©í•´í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'malicious' and weight < 0:
                    display_text = f"'{word}' í—¤ë”ì˜ íŠ¹ì • ê°’ì€ ì´ URLì´ ì•…ì„±ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ì™„í™”í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤."
                else:
                    display_text = f"'{word}' í—¤ë”ì˜ íŠ¹ì • ê°’ì´ ì´ URL íŒë‹¨ì— {('ê¸ì •ì ì¸' if weight > 0 else 'ë¶€ì •ì ì¸')} ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
            
            # --- ì¼ë°˜ì ì¸ URL êµ¬ì„± ìš”ì†Œ (ë„ë©”ì¸, ê²½ë¡œ ì¡°ê°, ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ë“±) ---
            # ìˆ«ìë¡œë§Œ ì´ë£¨ì–´ì§„ ë‹¨ì–´ëŠ” ë„ˆë¬´ í”í•˜ê³  ì˜ë¯¸ ì—†ìœ¼ë¯€ë¡œ ì œì™¸ 
            elif ('.' in word and len(word) > 2) or \
                 (len(word) <= 30 and all(c.isalnum() or c in ['-', '_', '%', '/', '.'] for c in word) and not word.isdigit()):
                meaning = "URLì˜ ê²½ë¡œë‚˜ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì— í¬í•¨ëœ ë¬¸ìì—´ íŒ¨í„´ì€ ì•…ì„± í–‰ìœ„(ì˜ˆ: í”¼ì‹±, ë©€ì›¨ì–´ ë°°í¬)ë¥¼ ìˆ¨ê¸°ê±°ë‚˜ ìœ ë„í•˜ê¸° ìœ„í•´ ë¹„ì •ìƒì ìœ¼ë¡œ êµ¬ì„±ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ë¹„ì •ìƒì ì¸ ê¸¸ì´, ë°˜ë³µë˜ëŠ” ë¬¸ìì—´, ì¸ì½”ë”©ëœ ë¬¸ìì—´ ë“±ì´ ì—¬ê¸°ì— í•´ë‹¹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                if current_predicted_label == 'malicious' and weight > 0:
                    display_text = f"URL ë‚´ì˜ '{word}' íŒ¨í„´ì´ ì´ URLì„ ì•…ì„±ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë° ê¸ì •ì ì¸ ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'benign' and weight < 0:
                    display_text = f"URL ë‚´ì˜ '{word}' íŒ¨í„´ì€ ì´ URLì´ ì •ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ë°©í•´í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤."
                elif current_predicted_label == 'malicious' and weight < 0:
                    display_text = f"URL ë‚´ì˜ '{word}' íŒ¨í„´ì€ ì´ URLì´ ì•…ì„±ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë‹¤ì†Œ ì™„í™”í•˜ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤."
                else:
                    display_text = f"URL ë‚´ì˜ '{word}' íŒ¨í„´ì´ ì´ URL íŒë‹¨ì— {('ê¸ì •ì ì¸' if weight > 0 else 'ë¶€ì •ì ì¸')} ì˜í–¥ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤."
            
            return display_text, meaning

        # --- ìš”ì•½ ì„¤ëª… ìƒì„± (reason_summary) ---
        significant_features_for_summary = []
        for word, weight in explanation_list:
            # LIMEì˜ as_listëŠ” (feature, weight) íŠœí”Œì„ ë°˜í™˜.
            # í•´ë‹¹ wordê°€ LIME ì„¤ëª… í•¨ìˆ˜ì— ì˜í•´ ìœ íš¨í•œ ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ”ì§€ í™•ì¸
            # ìš”ì•½ ëª©ì ì´ë¯€ë¡œ predicted_label_context_for_meaningì€ ë¹ˆ ë¬¸ìì—´ë¡œ ë„˜ê²¨ í•„í„°ë§ë§Œ ìˆ˜í–‰
            temp_desc_text, _ = get_understandable_explanation_text_and_meaning(word, weight, predicted_label) 

            # ìœ íš¨í•œ ì„¤ëª… í…ìŠ¤íŠ¸ê°€ ìˆê³ , ê¸°ì—¬ë„ ì„ê³„ê°’ì„ ë„˜ëŠ” ê²½ìš°ë§Œ ìš”ì•½ì— ê³ ë ¤
            if temp_desc_text and abs(weight) > 0.05: 
                # BENIGN ì˜ˆì¸¡ì¸ ê²½ìš°, ì–‘ìˆ˜ ê¸°ì—¬ë„ë¥¼ ê°€ì§„ íŠ¹ì§•ë§Œ 'ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íŒ¨í„´'ìœ¼ë¡œ ìš”ì•½
                if predicted_label == 'benign' and weight > 0:
                    significant_features_for_summary.append(word)
                # MALICIOUS ì˜ˆì¸¡ì¸ ê²½ìš°, ì–‘ìˆ˜ ê¸°ì—¬ë„ë¥¼ ê°€ì§„ íŠ¹ì§• (ì•…ì„± íŠ¹ì§•)ë§Œ 'ì •ìƒì ì´ì§€ ì•Šì€ íŒ¨í„´'ìœ¼ë¡œ ìš”ì•½
                elif predicted_label == 'malicious' and weight > 0:
                    # 'NOHEADER'ëŠ” íŠ¹ë³„íˆ ì²˜ë¦¬í•˜ì—¬ ìš”ì•½ì— ì§ì ‘ í‘œì‹œ
                    if word.lower() == 'noheader':
                        significant_features_for_summary.append("HTTP í—¤ë” ì •ë³´ ë¶€ì¬")
                    else:
                        significant_features_for_summary.append(word)
                # MALICIOUS ì˜ˆì¸¡ì¸ ê²½ìš°, ìŒìˆ˜ ê¸°ì—¬ë„ë¥¼ ê°€ì§„ ì‹ ë¢° ë„ë©”ì¸ë„ ìš”ì•½ì— í¬í•¨
                # ì´ ê²½ìš°ì—ëŠ” 'ì •ìƒ ì‚¬ì´íŠ¸ë¥¼ ëª¨ë°©í•˜ë ¤ëŠ” ì‹œë„'ë¼ëŠ” ë§¥ë½ìœ¼ë¡œ ì„¤ëª…í•  ê²ƒì„
                elif predicted_label == 'malicious' and weight < 0 and word.lower() in TRUSTED_DOMAINS_FOR_EXPLANATION:
                    significant_features_for_summary.append(f"{word} (ì‹ ë¢° ë„ë©”ì¸)")


        # ìš”ì•½ ë¬¸êµ¬ ìƒì„±
        if predicted_label == 'malicious':
            # 'NOHEADER'ê°€ significant_features_for_summaryì— ì´ë¯¸ ë“¤ì–´ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
            # ê·¸ë¦¬ê³  summaryì—ëŠ” ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ë³´ì—¬ì£¼ë˜, 'NOHEADER'ëŠ” í•­ìƒ ìµœìš°ì„ ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸° ìœ„í•´ íŠ¹ë³„íˆ ì²˜ë¦¬
            final_summary_features_display = [] # ìµœì¢… ìš”ì•½ ë¬¸êµ¬ì— í‘œì‹œë  íŠ¹ì§•ë“¤
            
            # 'HTTP í—¤ë” ì •ë³´ ë¶€ì¬'ëŠ” í•­ìƒ ìµœìš°ì„ ìœ¼ë¡œ í‘œì‹œ
            if "HTTP í—¤ë” ì •ë³´ ë¶€ì¬" in significant_features_for_summary:
                final_summary_features_display.append("HTTP í—¤ë” ì •ë³´ ë¶€ì¬")
                significant_features_for_summary.remove("HTTP í—¤ë” ì •ë³´ ë¶€ì¬") # ì¤‘ë³µ ë°©ì§€

            # ì‹ ë¢° ë„ë©”ì¸ (ìŒìˆ˜ ê¸°ì—¬)ì´ ìˆë‹¤ë©´ ë‹¤ìŒìœ¼ë¡œ í‘œì‹œ
            trusted_domains_in_summary = [f for f in significant_features_for_summary if "(ì‹ ë¢° ë„ë©”ì¸)" in f]
            for td in trusted_domains_in_summary:
                if len(final_summary_features_display) < 3: # ìµœëŒ€ 3ê°œê¹Œì§€
                    final_summary_features_display.append(td)
                    significant_features_for_summary.remove(td) # ì¤‘ë³µ ë°©ì§€

            # ë‚˜ë¨¸ì§€ ì•…ì„± íŒ¨í„´ íŠ¹ì§•ë“¤ ì¶”ê°€
            for other_feature in significant_features_for_summary:
                if len(final_summary_features_display) < 3: # ìµœëŒ€ 3ê°œê¹Œì§€
                    final_summary_features_display.append(other_feature)
            
            if final_summary_features_display:
                # ì‹ ë¢° ë„ë©”ì¸ í¬í•¨ ì—¬ë¶€ì— ë”°ë¼ ë©”ì‹œì§€ ì¡°ì •
                if any("(ì‹ ë¢° ë„ë©”ì¸)" in f for f in final_summary_features_display):
                    # ì‹ ë¢° ë„ë©”ì¸ì´ í¬í•¨ëœ ê²½ìš°, ì‚¬ì¹­ ê°€ëŠ¥ì„± ì–¸ê¸‰
                    reason_phrases.append(f"íŠ¹íˆ '{', '.join(final_summary_features_display).replace(' (ì‹ ë¢° ë„ë©”ì¸)', '')}'ê³¼ ê°™ì€ íŒ¨í„´ì€ ì•…ì„±ìœ¼ë¡œ ì˜ì‹¬ë˜ì§€ë§Œ, ì¼ë¶€ **ì‹ ë¢° ë„ë©”ì¸**ì´ í¬í•¨ë˜ì–´ ì •ìƒ ì‚¬ì´íŠ¸ë¥¼ ëª¨ë°©í•˜ë ¤ëŠ” ì‹œë„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    reason_phrases.append(f"íŠ¹íˆ '{', '.join(final_summary_features_display)}' ë“±ê³¼ ê°™ì´ **ì •ìƒì ì´ì§€ ì•Šì€ íŒ¨í„´**ì´ ì•…ì„±ìœ¼ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤.")
            else:
                reason_phrases.append("URLì˜ ì „ë°˜ì ì¸ êµ¬ì¡°ì™€ íŒ¨í„´ì´ ì•Œë ¤ì§„ ì•…ì„± URLê³¼ ìœ ì‚¬í•˜ì—¬ ì˜ì‹¬ë©ë‹ˆë‹¤.")
        else: # 'benign'
            if significant_features_for_summary:
                reason_phrases.append(f"ì´ URLì€ '{', '.join(significant_features_for_summary[:3])}' ë“±ê³¼ ê°™ì´ **ì¼ë°˜ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íŒ¨í„´**ì„ ê°€ì§€ê³  ìˆì–´ ì•ˆì „í•©ë‹ˆë‹¤.")
            else:
                reason_phrases.append("URLì˜ ì „ë°˜ì ì¸ êµ¬ì¡°ì™€ íŒ¨í„´ì´ ì•Œë ¤ì§„ ì •ìƒ URLê³¼ ìœ ì‚¬í•˜ì—¬ ì•ˆì „í•©ë‹ˆë‹¤.")

        reason_summary = "ì´ URLì€ " + predicted_label.upper() + "ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. " + " ".join(reason_phrases)

        # --- ìƒì„¸ ì„¤ëª… ì¶œë ¥ ---
        print("\n--- ìƒì„¸ ë¶„ì„ (URL íŠ¹ì§•ë³„ ê¸°ì—¬ë„) ---")
        print("ğŸ’¡ ì´ ì„¹ì…˜ì—ì„œëŠ” ëª¨ë¸ì´ URLì„ ë¶„ì„í•˜ë©° ì¤‘ìš”í•˜ê²Œ íŒë‹¨í•œ ì£¼ìš” íŠ¹ì§•ë“¤ê³¼ ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.")
        print("   'ê¸°ì—¬ë„'ëŠ” ê° íŠ¹ì§•ì´ ìµœì¢… íŒë‹¨ì— ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ ê¸°ì—¬í–ˆëŠ”ì§€ë¥¼ ìˆ«ìë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (ê°’ì´ í´ìˆ˜ë¡ ê¸°ì—¬ë„ ë†’ìŒ)\n")
        
        has_understandable_explanation = False
        for word, weight in explanation.as_list(label=predicted_class_id): 
            # get_understandable_explanation_text_and_meaning í•¨ìˆ˜ì— predicted_label ì¶”ê°€ ì „ë‹¬
            desc_text, meaning = get_understandable_explanation_text_and_meaning(word, weight, predicted_label)
            
            if desc_text and abs(weight) > 0.01: # ê¸°ì—¬ë„ê°€ 0.01 ì´ìƒì¸ ê²½ìš°ë§Œ ì¶œë ¥
                print(f"  - **íŠ¹ì§•**: {desc_text} (ê¸°ì—¬ë„: {weight:.4f})")
                if meaning:
                    print(f"    **ì„¤ëª…**: {meaning}\n")
                has_understandable_explanation = True
        
        if not has_understandable_explanation:
            print("ìë™ í•„í„°ë§ëœ ì£¼ìš” íŠ¹ì§•ì€ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ LIME ê²°ê³¼ì—ëŠ” ë³µì¡í•œ ë¬¸ìì—´ì´ë‚˜ ë¯¸ë¯¸í•œ ê¸°ì—¬ë„ê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("----------------------------")
        print("ğŸ’¡ ì´ ë¶„ì„ì€ ëª¨ë¸ì´ í•™ìŠµí•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•˜ë©°, ëª¨ë“  URLì— ëŒ€í•œ ì ˆëŒ€ì ì¸ íŒë‹¨ ê¸°ì¤€ì€ ì•„ë‹™ë‹ˆë‹¤. ")
        print("   ì˜ì‹¬ìŠ¤ëŸ¬ìš´ URLì€ ì§ì ‘ ì ‘ì†í•˜ê¸° ì „ ë°˜ë“œì‹œ ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n")


    except Exception as e:
        print(f"LIME ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        reason_summary = f"ì´ URLì€ {predicted_label.upper()}ë¡œ íŒë‹¨ë©ë‹ˆë‹¤ (í™•ì‹ ë„: {confidence:.2f}%)."
        explanation_list = []

    print(f"ë¶„ë¥˜ ê²°ê³¼: **{predicted_label.upper()}** (í™•ì‹ ë„: {confidence:.2f}%)")
    print(f"ì„¤ëª… ìš”ì•½: {reason_summary}")

    return {
        "predicted_label": predicted_label,
        "confidence": f"{confidence:.2f}%",
        "reason_summary": reason_summary,
        "detailed_explanation": explanation_list # ì›ë³¸ LIME ê²°ê³¼ë¥¼ ë°˜í™˜
    }