{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd68d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib) (11.2.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [fonttools]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e80145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/injeolmi/.conda/envs/env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bea3a49-deca-45ee-9d81-54a3ea336eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/injeolmi/.conda/envs/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d8dc1f-69fe-49dd-891d-cf37d57e76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dataPreprocessFromTXT(filename, input_ids, input_types, input_masks, labels):\n",
    "    pad_size = 200\n",
    "    # 로컬 vocab.txt 경로 지정\n",
    "    tokenizer = BertTokenizer(\n",
    "        vocab_file=\"../../bert_tokenizer/vocab.txt\",\n",
    "        do_lower_case=True\n",
    "    )\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        filename,\n",
    "        sep=\"\\t\", header=None,\n",
    "        names=[\"label\",\"url\"],\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Preprocess {filename}\"):\n",
    "        url = row[\"url\"]\n",
    "        y   = row[\"label\"]\n",
    "\n",
    "        tokens = tokenizer.tokenize(url)\n",
    "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "\n",
    "        ids   = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        masks = [1] * len(ids)\n",
    "        types = [0] * len(ids)\n",
    "\n",
    "        if len(ids) < pad_size:\n",
    "            pad_len = pad_size - len(ids)\n",
    "            ids   += [0] * pad_len\n",
    "            masks += [0] * pad_len\n",
    "            types += [0] * pad_len\n",
    "        else:\n",
    "            ids   = ids[:pad_size]\n",
    "            masks = masks[:pad_size]\n",
    "            types = types[:pad_size]\n",
    "\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_types.append(types)\n",
    "\n",
    "        # 5) 레이블 매핑: 문자열 'benign'→0, 'malicious'→1 (정수 0/2도 처리)\n",
    "        y_str = str(y).lower()\n",
    "        if y_str in (\"benign\", \"0\"):\n",
    "            labels.append(0)\n",
    "        elif y_str in (\"malicious\", \"2\"):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown label: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348233d-eb41-43d4-94e9-b960cedbf04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocess ../../dataset/train.txt: 100%|██████████| 79998/79998 [00:19<00:00, 4088.50it/s]\n",
      "Preprocess ../../dataset/test.txt: 100%|██████████| 20000/20000 [00:04<00:00, 4287.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# 학습용(Train)\n",
    "train_ids, train_types, train_masks, train_labels = [], [], [], []\n",
    "dataPreprocessFromTXT(\"../../dataset/train.txt\",\n",
    "                      train_ids, train_types, train_masks, train_labels)\n",
    "\n",
    "# 검증용(Validation)\n",
    "val_ids, val_types, val_masks, val_labels = [], [], [], []\n",
    "dataPreprocessFromTXT(\"../../dataset/test.txt\",\n",
    "                      val_ids, val_types, val_masks, val_labels)\n",
    "//train,val-train.txt, test-test.txt 사용 하기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e723a1b-b0e3-4ad4-b028-2fbc540e9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c10fa3-b14b-4dfa-8d37-b42e3301fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spiltDatast_bert(input_ids, input_types, input_masks, label):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets.\n",
    "\n",
    "    :param input_ids: List of input character IDs.\n",
    "    :param input_types: List of segment IDs.\n",
    "    :param input_masks: List of attention masks.\n",
    "    :param label: List of labels.\n",
    "    :return: Split datasets for training and testing.\n",
    "    \"\"\"\n",
    "    # Randomly shuffle the indices\n",
    "    random_order = list(range(len(input_ids)))\n",
    "    np.random.seed(2024)  # Fix the seed\n",
    "    np.random.shuffle(random_order)\n",
    "    print(random_order[:10])\n",
    "\n",
    "    # Split the dataset into 80% training and 20% testing\n",
    "    input_ids_train = np.array([input_ids[i] for i in random_order[:int(len(input_ids) * 0.8)]])\n",
    "    input_types_train = np.array([input_types[i] for i in random_order[:int(len(input_ids) * 0.8)]])\n",
    "    input_masks_train = np.array([input_masks[i] for i in random_order[:int(len(input_ids) * 0.8)]])\n",
    "    y_train = np.array([label[i] for i in random_order[:int(len(input_ids) * 0.8)]])\n",
    "    print(\"input_ids_train.shape:\" + str(input_ids_train.shape))\n",
    "    print(\"input_types_train.shape:\" + str(input_types_train.shape))\n",
    "    print(\"input_masks_train.shape:\" + str(input_masks_train.shape))\n",
    "    print(\"y_train.shape:\" + str(y_train.shape))\n",
    "\n",
    "    input_ids_test = np.array([input_ids[i] for i in random_order[int(len(input_ids) * 0.8):int(len(input_ids) * 1)]])\n",
    "    input_types_test = np.array([input_types[i] for i in random_order[int(len(input_ids) * 0.8):int(len(input_ids) * 1)]])\n",
    "    input_masks_test = np.array([input_masks[i] for i in random_order[int(len(input_ids) * 0.8):int(len(input_ids) * 1)]])\n",
    "    y_test = np.array([label[i] for i in random_order[int(len(input_ids) * 0.8):int(len(input_ids) * 1)]])\n",
    "    print(\"input_ids_test.shape:\" + str(input_ids_test.shape))\n",
    "    print(\"input_types_test.shape:\" + str(input_types_test.shape))\n",
    "    print(\"input_masks_test.shape:\" + str(input_masks_test.shape))\n",
    "    print(\"y_test.shape:\" + str(y_test.shape))\n",
    "\n",
    "    return input_ids_train, input_types_train, input_masks_train, y_train, input_ids_test, input_types_test, input_masks_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb77547f-ebff-4149-981e-a41e6b7f16b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79998\n",
      "79998\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids))\n",
    "print(len(train_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c555593-de4d-4520-bb68-c8c33a27b98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54744, 26671, 24586, 5189, 17246, 41963, 19535, 24723, 71407, 5982]\n",
      "input_ids_train.shape:(63998, 200)\n",
      "input_types_train.shape:(63998, 200)\n",
      "input_masks_train.shape:(63998, 200)\n",
      "y_train.shape:(63998,)\n",
      "input_ids_test.shape:(16000, 200)\n",
      "input_types_test.shape:(16000, 200)\n",
      "input_masks_test.shape:(16000, 200)\n",
      "y_test.shape:(16000,)\n"
     ]
    }
   ],
   "source": [
    "input_ids_train, input_types_train, input_masks_train, y_train, input_ids_val, input_types_val, input_masks_val, y_val = spiltDatast_bert(\n",
    "    train_ids, train_types, train_masks, train_labels\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_data = TensorDataset(torch.tensor(input_ids_train).to(DEVICE),\n",
    "                               torch.tensor(input_types_train).to(DEVICE),\n",
    "                               torch.tensor(input_masks_train).to(DEVICE),\n",
    "                               torch.tensor(y_train).to(DEVICE))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_data = TensorDataset(torch.tensor(input_ids_val).to(DEVICE),\n",
    "                              torch.tensor(input_types_val).to(DEVICE),\n",
    "                              torch.tensor(input_masks_val).to(DEVICE),\n",
    "                              torch.tensor(y_val).to(DEVICE))\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_loader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080b57b4-3220-4986-8928-5a6b77347c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 5000\n",
      "}\n",
      "\n",
      "BertForMaskedLM(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(5000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cls): BertOnlyMLMHead(\n",
      "    (predictions): BertLMPredictionHead(\n",
      "      (transform): BertPredictionHeadTransform(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (transform_act_fn): GELUActivation()\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (decoder): Linear(in_features=768, out_features=5000, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    ")\n",
    "\n",
    "config_kwargs = {\n",
    "    \"cache_dir\": None,\n",
    "    \"revision\": 'main',\n",
    "    \"use_auth_token\": None,\n",
    "    \"hidden_dropout_prob\": 0.1,\n",
    "    \"vocab_size\": 5000,\n",
    "}\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"../../bert_config\", **config_kwargs)\n",
    "print(config)\n",
    "\n",
    "bert_model = AutoModelForMaskedLM.from_config(\n",
    "    config=config,\n",
    ")\n",
    "bert_model.resize_token_embeddings(config_kwargs[\"vocab_size\"])\n",
    "print(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028f812b-1c00-4604-a499-01aa57f591fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.load_state_dict(\n",
    "    torch.load(\"../../bert_model/urlBERT (1).pt\", map_location=\"cpu\"),\n",
    "    strict=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f481942-b093-457b-81c0-49ff1917bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, bert, freeze=False):\n",
    "        super(BertForSequenceClassification, self).__init__()\n",
    "        self.bert = bert\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            param.requires_grad = True\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.classifier = nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = x[0]\n",
    "        types = x[1]\n",
    "        mask = x[2]\n",
    "        outputs = self.bert(context, attention_mask=mask, token_type_ids=types, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states[-1][:,0,:]\n",
    "        out = self.dropout(hidden_states)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ae863a-6585-41db-9f90-2c934ccb89b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(5000, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): Sequential()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification(bert_model)\n",
    "model.bert.cls = nn.Sequential()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65610ef0-e1a9-47a9-9b3b-3afc8125c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92aab9e8-bffa-4dc7-ac64-7be1cd37cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (x1, x2, x3, y) in enumerate(train_loader):\n",
    "        start_time = time.time()\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model([x1, x2, x3])\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = F.cross_entropy(y_pred, y.squeeze())\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.2f}%)]\\t Loss: {:.6f}'.format(epoch, (batch_idx + 1) * len(x1),\n",
    "                                                                            len(train_loader.dataset),\n",
    "                                                                            100. * batch_idx / len(train_loader),\n",
    "                                                                            loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afdb1dc5-485f-481a-9fed-6b710cdfbd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, test_loader):\n",
    "    \"\"\"\n",
    "    Perform model validation on the test data.\n",
    "\n",
    "    :param model: The model to be validated.\n",
    "    :param device: The device to run validation on (e.g., CPU or GPU).\n",
    "    :param test_loader: The data loader for test data.\n",
    "    :return: A tuple containing accuracy, precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for batch_idx, (x1, x2, x3, y) in enumerate(test_loader):\n",
    "        x1, x2, x3, y = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_ = model([x1, x2, x3])\n",
    "\n",
    "        test_loss += F.cross_entropy(y_, y.squeeze()).item()\n",
    "\n",
    "        pred = y_.max(-1, keepdim=True)[1]  # .max(): 2 outputs, representing the maximum value and its index\n",
    "\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(pred.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['benign', 'malware'],\n",
    "                yticklabels=['benign', 'malware'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "\n",
    "    # Save the confusion matrix plot\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {:.2f}%, Precision: {:.2f}%, Recall: {:.2f}%, F1: {:.2f}%'.format(\n",
    "        test_loss, accuracy * 100, precision * 100, recall * 100, f1 * 100))\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c51c64cf-3247-4849-92e4-c4f69df57891",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d932d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 프로젝트 폴더 안에 \"checkpoints\" 디렉터리를 만들기\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc1aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/63998 (9.90%)]\t Loss: 0.000985\n",
      "Train Epoch: 1 [12800/63998 (19.90%)]\t Loss: 0.057148\n",
      "Train Epoch: 1 [19200/63998 (29.90%)]\t Loss: 0.000896\n",
      "Train Epoch: 1 [25600/63998 (39.90%)]\t Loss: 0.022125\n",
      "Train Epoch: 1 [32000/63998 (49.90%)]\t Loss: 0.005868\n",
      "Train Epoch: 1 [38400/63998 (59.90%)]\t Loss: 0.000718\n",
      "Train Epoch: 1 [44800/63998 (69.90%)]\t Loss: 0.004419\n",
      "Train Epoch: 1 [51200/63998 (79.90%)]\t Loss: 0.000560\n",
      "Train Epoch: 1 [57600/63998 (89.90%)]\t Loss: 0.065237\n",
      "Train Epoch: 1 [62000/63998 (99.90%)]\t Loss: 0.156866\n",
      "Test set: Average loss: 0.0230, Accuracy: 99.24%, Precision: 98.71%, Recall: 99.80%, F1: 99.25%\n",
      "acc is: 0.9924, best acc is 0.9924\n",
      "Train Epoch: 2 [6400/63998 (9.90%)]\t Loss: 0.000508\n",
      "Train Epoch: 2 [12800/63998 (19.90%)]\t Loss: 0.000564\n",
      "Train Epoch: 2 [19200/63998 (29.90%)]\t Loss: 0.000379\n",
      "Train Epoch: 2 [25600/63998 (39.90%)]\t Loss: 0.007902\n",
      "Train Epoch: 2 [32000/63998 (49.90%)]\t Loss: 0.058860\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/modelx_URLBERT_80.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     acc, precision, recall, f1 \u001b[38;5;241m=\u001b[39m validation(model, DEVICE, val_loader)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_acc \u001b[38;5;241m<\u001b[39m acc:\n",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m x1, x2, x3, y \u001b[38;5;241m=\u001b[39m x1\u001b[38;5;241m.\u001b[39mto(device), x2\u001b[38;5;241m.\u001b[39mto(device), x3\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(y_pred, y\u001b[38;5;241m.\u001b[39msqueeze())\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m types \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m mask \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[1;32m     16\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1301\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;124;03m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;124;03m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1301\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1316\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:982\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    975\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_causal_attention_mask_for_sdpa(\n\u001b[1;32m    976\u001b[0m             attention_mask,\n\u001b[1;32m    977\u001b[0m             input_shape,\n\u001b[1;32m    978\u001b[0m             embedding_output,\n\u001b[1;32m    979\u001b[0m             past_key_values_length,\n\u001b[1;32m    980\u001b[0m         )\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_length\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:448\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[0;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[1;32m    445\u001b[0m is_tracing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mProxy) \u001b[38;5;129;01mor\u001b[39;00m is_torchdynamo_compiling()\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture data-dependent controlflows.\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "NUM_EPOCHS = 3\n",
    "PATH = \"checkpoints/modelx_URLBERT_80.pth\"\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    acc, precision, recall, f1 = validation(model, DEVICE, val_loader)\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "    print(\"acc is: {:.4f}, best acc is {:.4f}\".format(acc, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3c5e78a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\". \n\tUnexpected key(s) in state_dict: \"bert.bert.embeddings.word_embeddings.weight\", \"bert.bert.embeddings.position_embeddings.weight\", \"bert.bert.embeddings.token_type_embeddings.weight\", \"bert.bert.embeddings.LayerNorm.weight\", \"bert.bert.embeddings.LayerNorm.bias\", \"bert.bert.encoder.layer.0.attention.self.query.weight\", \"bert.bert.encoder.layer.0.attention.self.query.bias\", \"bert.bert.encoder.layer.0.attention.self.key.weight\", \"bert.bert.encoder.layer.0.attention.self.key.bias\", \"bert.bert.encoder.layer.0.attention.self.value.weight\", \"bert.bert.encoder.layer.0.attention.self.value.bias\", \"bert.bert.encoder.layer.0.attention.output.dense.weight\", \"bert.bert.encoder.layer.0.attention.output.dense.bias\", \"bert.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.0.intermediate.dense.weight\", \"bert.bert.encoder.layer.0.intermediate.dense.bias\", \"bert.bert.encoder.layer.0.output.dense.weight\", \"bert.bert.encoder.layer.0.output.dense.bias\", \"bert.bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.bert.encoder.layer.1.attention.self.query.weight\", \"bert.bert.encoder.layer.1.attention.self.query.bias\", \"bert.bert.encoder.layer.1.attention.self.key.weight\", \"bert.bert.encoder.layer.1.attention.self.key.bias\", \"bert.bert.encoder.layer.1.attention.self.value.weight\", \"bert.bert.encoder.layer.1.attention.self.value.bias\", \"bert.bert.encoder.layer.1.attention.output.dense.weight\", \"bert.bert.encoder.layer.1.attention.output.dense.bias\", \"bert.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.1.intermediate.dense.weight\", \"bert.bert.encoder.layer.1.intermediate.dense.bias\", \"bert.bert.encoder.layer.1.output.dense.weight\", \"bert.bert.encoder.layer.1.output.dense.bias\", \"bert.bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.bert.encoder.layer.2.attention.self.query.weight\", \"bert.bert.encoder.layer.2.attention.self.query.bias\", \"bert.bert.encoder.layer.2.attention.self.key.weight\", \"bert.bert.encoder.layer.2.attention.self.key.bias\", \"bert.bert.encoder.layer.2.attention.self.value.weight\", \"bert.bert.encoder.layer.2.attention.self.value.bias\", \"bert.bert.encoder.layer.2.attention.output.dense.weight\", \"bert.bert.encoder.layer.2.attention.output.dense.bias\", \"bert.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.2.intermediate.dense.weight\", \"bert.bert.encoder.layer.2.intermediate.dense.bias\", \"bert.bert.encoder.layer.2.output.dense.weight\", \"bert.bert.encoder.layer.2.output.dense.bias\", \"bert.bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.bert.encoder.layer.3.attention.self.query.weight\", \"bert.bert.encoder.layer.3.attention.self.query.bias\", \"bert.bert.encoder.layer.3.attention.self.key.weight\", \"bert.bert.encoder.layer.3.attention.self.key.bias\", \"bert.bert.encoder.layer.3.attention.self.value.weight\", \"bert.bert.encoder.layer.3.attention.self.value.bias\", \"bert.bert.encoder.layer.3.attention.output.dense.weight\", \"bert.bert.encoder.layer.3.attention.output.dense.bias\", \"bert.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.3.intermediate.dense.weight\", \"bert.bert.encoder.layer.3.intermediate.dense.bias\", \"bert.bert.encoder.layer.3.output.dense.weight\", \"bert.bert.encoder.layer.3.output.dense.bias\", \"bert.bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.bert.encoder.layer.4.attention.self.query.weight\", \"bert.bert.encoder.layer.4.attention.self.query.bias\", \"bert.bert.encoder.layer.4.attention.self.key.weight\", \"bert.bert.encoder.layer.4.attention.self.key.bias\", \"bert.bert.encoder.layer.4.attention.self.value.weight\", \"bert.bert.encoder.layer.4.attention.self.value.bias\", \"bert.bert.encoder.layer.4.attention.output.dense.weight\", \"bert.bert.encoder.layer.4.attention.output.dense.bias\", \"bert.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.4.intermediate.dense.weight\", \"bert.bert.encoder.layer.4.intermediate.dense.bias\", \"bert.bert.encoder.layer.4.output.dense.weight\", \"bert.bert.encoder.layer.4.output.dense.bias\", \"bert.bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.bert.encoder.layer.5.attention.self.query.weight\", \"bert.bert.encoder.layer.5.attention.self.query.bias\", \"bert.bert.encoder.layer.5.attention.self.key.weight\", \"bert.bert.encoder.layer.5.attention.self.key.bias\", \"bert.bert.encoder.layer.5.attention.self.value.weight\", \"bert.bert.encoder.layer.5.attention.self.value.bias\", \"bert.bert.encoder.layer.5.attention.output.dense.weight\", \"bert.bert.encoder.layer.5.attention.output.dense.bias\", \"bert.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.5.intermediate.dense.weight\", \"bert.bert.encoder.layer.5.intermediate.dense.bias\", \"bert.bert.encoder.layer.5.output.dense.weight\", \"bert.bert.encoder.layer.5.output.dense.bias\", \"bert.bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.bert.encoder.layer.6.attention.self.query.weight\", \"bert.bert.encoder.layer.6.attention.self.query.bias\", \"bert.bert.encoder.layer.6.attention.self.key.weight\", \"bert.bert.encoder.layer.6.attention.self.key.bias\", \"bert.bert.encoder.layer.6.attention.self.value.weight\", \"bert.bert.encoder.layer.6.attention.self.value.bias\", \"bert.bert.encoder.layer.6.attention.output.dense.weight\", \"bert.bert.encoder.layer.6.attention.output.dense.bias\", \"bert.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.6.intermediate.dense.weight\", \"bert.bert.encoder.layer.6.intermediate.dense.bias\", \"bert.bert.encoder.layer.6.output.dense.weight\", \"bert.bert.encoder.layer.6.output.dense.bias\", \"bert.bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.bert.encoder.layer.7.attention.self.query.weight\", \"bert.bert.encoder.layer.7.attention.self.query.bias\", \"bert.bert.encoder.layer.7.attention.self.key.weight\", \"bert.bert.encoder.layer.7.attention.self.key.bias\", \"bert.bert.encoder.layer.7.attention.self.value.weight\", \"bert.bert.encoder.layer.7.attention.self.value.bias\", \"bert.bert.encoder.layer.7.attention.output.dense.weight\", \"bert.bert.encoder.layer.7.attention.output.dense.bias\", \"bert.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.7.intermediate.dense.weight\", \"bert.bert.encoder.layer.7.intermediate.dense.bias\", \"bert.bert.encoder.layer.7.output.dense.weight\", \"bert.bert.encoder.layer.7.output.dense.bias\", \"bert.bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.bert.encoder.layer.8.attention.self.query.weight\", \"bert.bert.encoder.layer.8.attention.self.query.bias\", \"bert.bert.encoder.layer.8.attention.self.key.weight\", \"bert.bert.encoder.layer.8.attention.self.key.bias\", \"bert.bert.encoder.layer.8.attention.self.value.weight\", \"bert.bert.encoder.layer.8.attention.self.value.bias\", \"bert.bert.encoder.layer.8.attention.output.dense.weight\", \"bert.bert.encoder.layer.8.attention.output.dense.bias\", \"bert.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.8.intermediate.dense.weight\", \"bert.bert.encoder.layer.8.intermediate.dense.bias\", \"bert.bert.encoder.layer.8.output.dense.weight\", \"bert.bert.encoder.layer.8.output.dense.bias\", \"bert.bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.bert.encoder.layer.9.attention.self.query.weight\", \"bert.bert.encoder.layer.9.attention.self.query.bias\", \"bert.bert.encoder.layer.9.attention.self.key.weight\", \"bert.bert.encoder.layer.9.attention.self.key.bias\", \"bert.bert.encoder.layer.9.attention.self.value.weight\", \"bert.bert.encoder.layer.9.attention.self.value.bias\", \"bert.bert.encoder.layer.9.attention.output.dense.weight\", \"bert.bert.encoder.layer.9.attention.output.dense.bias\", \"bert.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.9.intermediate.dense.weight\", \"bert.bert.encoder.layer.9.intermediate.dense.bias\", \"bert.bert.encoder.layer.9.output.dense.weight\", \"bert.bert.encoder.layer.9.output.dense.bias\", \"bert.bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.bert.encoder.layer.10.attention.self.query.weight\", \"bert.bert.encoder.layer.10.attention.self.query.bias\", \"bert.bert.encoder.layer.10.attention.self.key.weight\", \"bert.bert.encoder.layer.10.attention.self.key.bias\", \"bert.bert.encoder.layer.10.attention.self.value.weight\", \"bert.bert.encoder.layer.10.attention.self.value.bias\", \"bert.bert.encoder.layer.10.attention.output.dense.weight\", \"bert.bert.encoder.layer.10.attention.output.dense.bias\", \"bert.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.10.intermediate.dense.weight\", \"bert.bert.encoder.layer.10.intermediate.dense.bias\", \"bert.bert.encoder.layer.10.output.dense.weight\", \"bert.bert.encoder.layer.10.output.dense.bias\", \"bert.bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.bert.encoder.layer.11.attention.self.query.weight\", \"bert.bert.encoder.layer.11.attention.self.query.bias\", \"bert.bert.encoder.layer.11.attention.self.key.weight\", \"bert.bert.encoder.layer.11.attention.self.key.bias\", \"bert.bert.encoder.layer.11.attention.self.value.weight\", \"bert.bert.encoder.layer.11.attention.self.value.bias\", \"bert.bert.encoder.layer.11.attention.output.dense.weight\", \"bert.bert.encoder.layer.11.attention.output.dense.bias\", \"bert.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.11.intermediate.dense.weight\", \"bert.bert.encoder.layer.11.intermediate.dense.bias\", \"bert.bert.encoder.layer.11.output.dense.weight\", \"bert.bert.encoder.layer.11.output.dense.bias\", \"bert.bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.bert.encoder.layer.11.output.LayerNorm.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/modelx_URLBERT_80.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path, map_location\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.9/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\". \n\tUnexpected key(s) in state_dict: \"bert.bert.embeddings.word_embeddings.weight\", \"bert.bert.embeddings.position_embeddings.weight\", \"bert.bert.embeddings.token_type_embeddings.weight\", \"bert.bert.embeddings.LayerNorm.weight\", \"bert.bert.embeddings.LayerNorm.bias\", \"bert.bert.encoder.layer.0.attention.self.query.weight\", \"bert.bert.encoder.layer.0.attention.self.query.bias\", \"bert.bert.encoder.layer.0.attention.self.key.weight\", \"bert.bert.encoder.layer.0.attention.self.key.bias\", \"bert.bert.encoder.layer.0.attention.self.value.weight\", \"bert.bert.encoder.layer.0.attention.self.value.bias\", \"bert.bert.encoder.layer.0.attention.output.dense.weight\", \"bert.bert.encoder.layer.0.attention.output.dense.bias\", \"bert.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.0.intermediate.dense.weight\", \"bert.bert.encoder.layer.0.intermediate.dense.bias\", \"bert.bert.encoder.layer.0.output.dense.weight\", \"bert.bert.encoder.layer.0.output.dense.bias\", \"bert.bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.bert.encoder.layer.1.attention.self.query.weight\", \"bert.bert.encoder.layer.1.attention.self.query.bias\", \"bert.bert.encoder.layer.1.attention.self.key.weight\", \"bert.bert.encoder.layer.1.attention.self.key.bias\", \"bert.bert.encoder.layer.1.attention.self.value.weight\", \"bert.bert.encoder.layer.1.attention.self.value.bias\", \"bert.bert.encoder.layer.1.attention.output.dense.weight\", \"bert.bert.encoder.layer.1.attention.output.dense.bias\", \"bert.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.1.intermediate.dense.weight\", \"bert.bert.encoder.layer.1.intermediate.dense.bias\", \"bert.bert.encoder.layer.1.output.dense.weight\", \"bert.bert.encoder.layer.1.output.dense.bias\", \"bert.bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.bert.encoder.layer.2.attention.self.query.weight\", \"bert.bert.encoder.layer.2.attention.self.query.bias\", \"bert.bert.encoder.layer.2.attention.self.key.weight\", \"bert.bert.encoder.layer.2.attention.self.key.bias\", \"bert.bert.encoder.layer.2.attention.self.value.weight\", \"bert.bert.encoder.layer.2.attention.self.value.bias\", \"bert.bert.encoder.layer.2.attention.output.dense.weight\", \"bert.bert.encoder.layer.2.attention.output.dense.bias\", \"bert.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.2.intermediate.dense.weight\", \"bert.bert.encoder.layer.2.intermediate.dense.bias\", \"bert.bert.encoder.layer.2.output.dense.weight\", \"bert.bert.encoder.layer.2.output.dense.bias\", \"bert.bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.bert.encoder.layer.3.attention.self.query.weight\", \"bert.bert.encoder.layer.3.attention.self.query.bias\", \"bert.bert.encoder.layer.3.attention.self.key.weight\", \"bert.bert.encoder.layer.3.attention.self.key.bias\", \"bert.bert.encoder.layer.3.attention.self.value.weight\", \"bert.bert.encoder.layer.3.attention.self.value.bias\", \"bert.bert.encoder.layer.3.attention.output.dense.weight\", \"bert.bert.encoder.layer.3.attention.output.dense.bias\", \"bert.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.3.intermediate.dense.weight\", \"bert.bert.encoder.layer.3.intermediate.dense.bias\", \"bert.bert.encoder.layer.3.output.dense.weight\", \"bert.bert.encoder.layer.3.output.dense.bias\", \"bert.bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.bert.encoder.layer.4.attention.self.query.weight\", \"bert.bert.encoder.layer.4.attention.self.query.bias\", \"bert.bert.encoder.layer.4.attention.self.key.weight\", \"bert.bert.encoder.layer.4.attention.self.key.bias\", \"bert.bert.encoder.layer.4.attention.self.value.weight\", \"bert.bert.encoder.layer.4.attention.self.value.bias\", \"bert.bert.encoder.layer.4.attention.output.dense.weight\", \"bert.bert.encoder.layer.4.attention.output.dense.bias\", \"bert.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.4.intermediate.dense.weight\", \"bert.bert.encoder.layer.4.intermediate.dense.bias\", \"bert.bert.encoder.layer.4.output.dense.weight\", \"bert.bert.encoder.layer.4.output.dense.bias\", \"bert.bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.bert.encoder.layer.5.attention.self.query.weight\", \"bert.bert.encoder.layer.5.attention.self.query.bias\", \"bert.bert.encoder.layer.5.attention.self.key.weight\", \"bert.bert.encoder.layer.5.attention.self.key.bias\", \"bert.bert.encoder.layer.5.attention.self.value.weight\", \"bert.bert.encoder.layer.5.attention.self.value.bias\", \"bert.bert.encoder.layer.5.attention.output.dense.weight\", \"bert.bert.encoder.layer.5.attention.output.dense.bias\", \"bert.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.5.intermediate.dense.weight\", \"bert.bert.encoder.layer.5.intermediate.dense.bias\", \"bert.bert.encoder.layer.5.output.dense.weight\", \"bert.bert.encoder.layer.5.output.dense.bias\", \"bert.bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.bert.encoder.layer.6.attention.self.query.weight\", \"bert.bert.encoder.layer.6.attention.self.query.bias\", \"bert.bert.encoder.layer.6.attention.self.key.weight\", \"bert.bert.encoder.layer.6.attention.self.key.bias\", \"bert.bert.encoder.layer.6.attention.self.value.weight\", \"bert.bert.encoder.layer.6.attention.self.value.bias\", \"bert.bert.encoder.layer.6.attention.output.dense.weight\", \"bert.bert.encoder.layer.6.attention.output.dense.bias\", \"bert.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.6.intermediate.dense.weight\", \"bert.bert.encoder.layer.6.intermediate.dense.bias\", \"bert.bert.encoder.layer.6.output.dense.weight\", \"bert.bert.encoder.layer.6.output.dense.bias\", \"bert.bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.bert.encoder.layer.7.attention.self.query.weight\", \"bert.bert.encoder.layer.7.attention.self.query.bias\", \"bert.bert.encoder.layer.7.attention.self.key.weight\", \"bert.bert.encoder.layer.7.attention.self.key.bias\", \"bert.bert.encoder.layer.7.attention.self.value.weight\", \"bert.bert.encoder.layer.7.attention.self.value.bias\", \"bert.bert.encoder.layer.7.attention.output.dense.weight\", \"bert.bert.encoder.layer.7.attention.output.dense.bias\", \"bert.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.7.intermediate.dense.weight\", \"bert.bert.encoder.layer.7.intermediate.dense.bias\", \"bert.bert.encoder.layer.7.output.dense.weight\", \"bert.bert.encoder.layer.7.output.dense.bias\", \"bert.bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.bert.encoder.layer.8.attention.self.query.weight\", \"bert.bert.encoder.layer.8.attention.self.query.bias\", \"bert.bert.encoder.layer.8.attention.self.key.weight\", \"bert.bert.encoder.layer.8.attention.self.key.bias\", \"bert.bert.encoder.layer.8.attention.self.value.weight\", \"bert.bert.encoder.layer.8.attention.self.value.bias\", \"bert.bert.encoder.layer.8.attention.output.dense.weight\", \"bert.bert.encoder.layer.8.attention.output.dense.bias\", \"bert.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.8.intermediate.dense.weight\", \"bert.bert.encoder.layer.8.intermediate.dense.bias\", \"bert.bert.encoder.layer.8.output.dense.weight\", \"bert.bert.encoder.layer.8.output.dense.bias\", \"bert.bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.bert.encoder.layer.9.attention.self.query.weight\", \"bert.bert.encoder.layer.9.attention.self.query.bias\", \"bert.bert.encoder.layer.9.attention.self.key.weight\", \"bert.bert.encoder.layer.9.attention.self.key.bias\", \"bert.bert.encoder.layer.9.attention.self.value.weight\", \"bert.bert.encoder.layer.9.attention.self.value.bias\", \"bert.bert.encoder.layer.9.attention.output.dense.weight\", \"bert.bert.encoder.layer.9.attention.output.dense.bias\", \"bert.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.9.intermediate.dense.weight\", \"bert.bert.encoder.layer.9.intermediate.dense.bias\", \"bert.bert.encoder.layer.9.output.dense.weight\", \"bert.bert.encoder.layer.9.output.dense.bias\", \"bert.bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.bert.encoder.layer.10.attention.self.query.weight\", \"bert.bert.encoder.layer.10.attention.self.query.bias\", \"bert.bert.encoder.layer.10.attention.self.key.weight\", \"bert.bert.encoder.layer.10.attention.self.key.bias\", \"bert.bert.encoder.layer.10.attention.self.value.weight\", \"bert.bert.encoder.layer.10.attention.self.value.bias\", \"bert.bert.encoder.layer.10.attention.output.dense.weight\", \"bert.bert.encoder.layer.10.attention.output.dense.bias\", \"bert.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.10.intermediate.dense.weight\", \"bert.bert.encoder.layer.10.intermediate.dense.bias\", \"bert.bert.encoder.layer.10.output.dense.weight\", \"bert.bert.encoder.layer.10.output.dense.bias\", \"bert.bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.bert.encoder.layer.11.attention.self.query.weight\", \"bert.bert.encoder.layer.11.attention.self.query.bias\", \"bert.bert.encoder.layer.11.attention.self.key.weight\", \"bert.bert.encoder.layer.11.attention.self.key.bias\", \"bert.bert.encoder.layer.11.attention.self.value.weight\", \"bert.bert.encoder.layer.11.attention.self.value.bias\", \"bert.bert.encoder.layer.11.attention.output.dense.weight\", \"bert.bert.encoder.layer.11.attention.output.dense.bias\", \"bert.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.11.intermediate.dense.weight\", \"bert.bert.encoder.layer.11.intermediate.dense.bias\", \"bert.bert.encoder.layer.11.output.dense.weight\", \"bert.bert.encoder.layer.11.output.dense.bias\", \"bert.bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.bert.encoder.layer.11.output.LayerNorm.bias\". "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM, BertTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "# 1) 토크나이저 로드 (vocab.txt 위치가 맞아야 합니다)\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "tokenizer = BertTokenizer(\n",
    "    vocab_file=\"../../bert_tokenizer/vocab.txt\",\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "# 2) 베이스 BERT 모델(사전학습된 MaskedLM) 불러오기\n",
    "#    – config.json 을 AutoConfig.from_pretrained 로 읽어 옵니다.\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"../../bert_config\",   # 이 폴더 안에 config.json 이 있어야 함\n",
    "    hidden_dropout_prob=0.1,\n",
    "    vocab_size=tokenizer.vocab_size\n",
    ")\n",
    "\n",
    "base_bert = AutoModelForMaskedLM.from_config(config)\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "# 3) 커스텀 분류 모델 정의 (이전과 동일)\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, bert, num_labels=2, dropout_prob=0.1, freeze=False):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        if freeze:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.dropout   = nn.Dropout(p=dropout_prob)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        cls_repr = outputs.hidden_states[-1][:, 0, :]  # [CLS] 토큰 임베딩\n",
    "        x = self.dropout(cls_repr)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "# 4) 분류 모델에 베이스 BERT 연결 및 파인튜닝 체크포인트 로드\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "model = BertForSequenceClassification(\n",
    "    bert=base_bert.bert,  # AutoModelForMaskedLM 내부의 .bert 부분\n",
    "    num_labels=2,\n",
    "    dropout_prob=0.1,\n",
    "    freeze=False\n",
    ")\n",
    "\n",
    "checkpoint_path = \"checkpoints/modelx_URLBERT_80.pth\"\n",
    "state_dict = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "# 5) 새로운 URL을 분류하는 함수\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "def predict_url_probabilities(url: str):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        url,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids      = encoded[\"input_ids\"].to(DEVICE)\n",
    "    token_type_ids = encoded[\"token_type_ids\"].to(DEVICE)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, token_type_ids, attention_mask)\n",
    "        probs  = F.softmax(logits, dim=1)\n",
    "\n",
    "    return {\n",
    "        \"benign (%)\":    round(probs[0, 0].item() * 100, 2),\n",
    "        \"malicious (%)\": round(probs[0, 1].item() * 100, 2)\n",
    "    }\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "# 6) 실제로 테스트해 보기\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    test_urls = [\n",
    "        \"https://kebhana.com/\",\n",
    "        \"https://sites.google.com/view/update-currently1031/update\"\n",
    "    ]\n",
    "    for url in test_urls:\n",
    "        result = predict_url_probabilities(url)\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\" → 정상(benign) 확률   : {result['benign (%)']}%\")\n",
    "        print(f\" → 악성(malicious) 확률: {result['malicious (%)']}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9549647",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\". \n\tUnexpected key(s) in state_dict: \"bert.bert.embeddings.word_embeddings.weight\", \"bert.bert.embeddings.position_embeddings.weight\", \"bert.bert.embeddings.token_type_embeddings.weight\", \"bert.bert.embeddings.LayerNorm.weight\", \"bert.bert.embeddings.LayerNorm.bias\", \"bert.bert.encoder.layer.0.attention.self.query.weight\", \"bert.bert.encoder.layer.0.attention.self.query.bias\", \"bert.bert.encoder.layer.0.attention.self.key.weight\", \"bert.bert.encoder.layer.0.attention.self.key.bias\", \"bert.bert.encoder.layer.0.attention.self.value.weight\", \"bert.bert.encoder.layer.0.attention.self.value.bias\", \"bert.bert.encoder.layer.0.attention.output.dense.weight\", \"bert.bert.encoder.layer.0.attention.output.dense.bias\", \"bert.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.0.intermediate.dense.weight\", \"bert.bert.encoder.layer.0.intermediate.dense.bias\", \"bert.bert.encoder.layer.0.output.dense.weight\", \"bert.bert.encoder.layer.0.output.dense.bias\", \"bert.bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.bert.encoder.layer.1.attention.self.query.weight\", \"bert.bert.encoder.layer.1.attention.self.query.bias\", \"bert.bert.encoder.layer.1.attention.self.key.weight\", \"bert.bert.encoder.layer.1.attention.self.key.bias\", \"bert.bert.encoder.layer.1.attention.self.value.weight\", \"bert.bert.encoder.layer.1.attention.self.value.bias\", \"bert.bert.encoder.layer.1.attention.output.dense.weight\", \"bert.bert.encoder.layer.1.attention.output.dense.bias\", \"bert.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.1.intermediate.dense.weight\", \"bert.bert.encoder.layer.1.intermediate.dense.bias\", \"bert.bert.encoder.layer.1.output.dense.weight\", \"bert.bert.encoder.layer.1.output.dense.bias\", \"bert.bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.bert.encoder.layer.2.attention.self.query.weight\", \"bert.bert.encoder.layer.2.attention.self.query.bias\", \"bert.bert.encoder.layer.2.attention.self.key.weight\", \"bert.bert.encoder.layer.2.attention.self.key.bias\", \"bert.bert.encoder.layer.2.attention.self.value.weight\", \"bert.bert.encoder.layer.2.attention.self.value.bias\", \"bert.bert.encoder.layer.2.attention.output.dense.weight\", \"bert.bert.encoder.layer.2.attention.output.dense.bias\", \"bert.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.2.intermediate.dense.weight\", \"bert.bert.encoder.layer.2.intermediate.dense.bias\", \"bert.bert.encoder.layer.2.output.dense.weight\", \"bert.bert.encoder.layer.2.output.dense.bias\", \"bert.bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.bert.encoder.layer.3.attention.self.query.weight\", \"bert.bert.encoder.layer.3.attention.self.query.bias\", \"bert.bert.encoder.layer.3.attention.self.key.weight\", \"bert.bert.encoder.layer.3.attention.self.key.bias\", \"bert.bert.encoder.layer.3.attention.self.value.weight\", \"bert.bert.encoder.layer.3.attention.self.value.bias\", \"bert.bert.encoder.layer.3.attention.output.dense.weight\", \"bert.bert.encoder.layer.3.attention.output.dense.bias\", \"bert.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.3.intermediate.dense.weight\", \"bert.bert.encoder.layer.3.intermediate.dense.bias\", \"bert.bert.encoder.layer.3.output.dense.weight\", \"bert.bert.encoder.layer.3.output.dense.bias\", \"bert.bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.bert.encoder.layer.4.attention.self.query.weight\", \"bert.bert.encoder.layer.4.attention.self.query.bias\", \"bert.bert.encoder.layer.4.attention.self.key.weight\", \"bert.bert.encoder.layer.4.attention.self.key.bias\", \"bert.bert.encoder.layer.4.attention.self.value.weight\", \"bert.bert.encoder.layer.4.attention.self.value.bias\", \"bert.bert.encoder.layer.4.attention.output.dense.weight\", \"bert.bert.encoder.layer.4.attention.output.dense.bias\", \"bert.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.4.intermediate.dense.weight\", \"bert.bert.encoder.layer.4.intermediate.dense.bias\", \"bert.bert.encoder.layer.4.output.dense.weight\", \"bert.bert.encoder.layer.4.output.dense.bias\", \"bert.bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.bert.encoder.layer.5.attention.self.query.weight\", \"bert.bert.encoder.layer.5.attention.self.query.bias\", \"bert.bert.encoder.layer.5.attention.self.key.weight\", \"bert.bert.encoder.layer.5.attention.self.key.bias\", \"bert.bert.encoder.layer.5.attention.self.value.weight\", \"bert.bert.encoder.layer.5.attention.self.value.bias\", \"bert.bert.encoder.layer.5.attention.output.dense.weight\", \"bert.bert.encoder.layer.5.attention.output.dense.bias\", \"bert.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.5.intermediate.dense.weight\", \"bert.bert.encoder.layer.5.intermediate.dense.bias\", \"bert.bert.encoder.layer.5.output.dense.weight\", \"bert.bert.encoder.layer.5.output.dense.bias\", \"bert.bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.bert.encoder.layer.6.attention.self.query.weight\", \"bert.bert.encoder.layer.6.attention.self.query.bias\", \"bert.bert.encoder.layer.6.attention.self.key.weight\", \"bert.bert.encoder.layer.6.attention.self.key.bias\", \"bert.bert.encoder.layer.6.attention.self.value.weight\", \"bert.bert.encoder.layer.6.attention.self.value.bias\", \"bert.bert.encoder.layer.6.attention.output.dense.weight\", \"bert.bert.encoder.layer.6.attention.output.dense.bias\", \"bert.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.6.intermediate.dense.weight\", \"bert.bert.encoder.layer.6.intermediate.dense.bias\", \"bert.bert.encoder.layer.6.output.dense.weight\", \"bert.bert.encoder.layer.6.output.dense.bias\", \"bert.bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.bert.encoder.layer.7.attention.self.query.weight\", \"bert.bert.encoder.layer.7.attention.self.query.bias\", \"bert.bert.encoder.layer.7.attention.self.key.weight\", \"bert.bert.encoder.layer.7.attention.self.key.bias\", \"bert.bert.encoder.layer.7.attention.self.value.weight\", \"bert.bert.encoder.layer.7.attention.self.value.bias\", \"bert.bert.encoder.layer.7.attention.output.dense.weight\", \"bert.bert.encoder.layer.7.attention.output.dense.bias\", \"bert.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.7.intermediate.dense.weight\", \"bert.bert.encoder.layer.7.intermediate.dense.bias\", \"bert.bert.encoder.layer.7.output.dense.weight\", \"bert.bert.encoder.layer.7.output.dense.bias\", \"bert.bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.bert.encoder.layer.8.attention.self.query.weight\", \"bert.bert.encoder.layer.8.attention.self.query.bias\", \"bert.bert.encoder.layer.8.attention.self.key.weight\", \"bert.bert.encoder.layer.8.attention.self.key.bias\", \"bert.bert.encoder.layer.8.attention.self.value.weight\", \"bert.bert.encoder.layer.8.attention.self.value.bias\", \"bert.bert.encoder.layer.8.attention.output.dense.weight\", \"bert.bert.encoder.layer.8.attention.output.dense.bias\", \"bert.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.8.intermediate.dense.weight\", \"bert.bert.encoder.layer.8.intermediate.dense.bias\", \"bert.bert.encoder.layer.8.output.dense.weight\", \"bert.bert.encoder.layer.8.output.dense.bias\", \"bert.bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.bert.encoder.layer.9.attention.self.query.weight\", \"bert.bert.encoder.layer.9.attention.self.query.bias\", \"bert.bert.encoder.layer.9.attention.self.key.weight\", \"bert.bert.encoder.layer.9.attention.self.key.bias\", \"bert.bert.encoder.layer.9.attention.self.value.weight\", \"bert.bert.encoder.layer.9.attention.self.value.bias\", \"bert.bert.encoder.layer.9.attention.output.dense.weight\", \"bert.bert.encoder.layer.9.attention.output.dense.bias\", \"bert.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.9.intermediate.dense.weight\", \"bert.bert.encoder.layer.9.intermediate.dense.bias\", \"bert.bert.encoder.layer.9.output.dense.weight\", \"bert.bert.encoder.layer.9.output.dense.bias\", \"bert.bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.bert.encoder.layer.10.attention.self.query.weight\", \"bert.bert.encoder.layer.10.attention.self.query.bias\", \"bert.bert.encoder.layer.10.attention.self.key.weight\", \"bert.bert.encoder.layer.10.attention.self.key.bias\", \"bert.bert.encoder.layer.10.attention.self.value.weight\", \"bert.bert.encoder.layer.10.attention.self.value.bias\", \"bert.bert.encoder.layer.10.attention.output.dense.weight\", \"bert.bert.encoder.layer.10.attention.output.dense.bias\", \"bert.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.10.intermediate.dense.weight\", \"bert.bert.encoder.layer.10.intermediate.dense.bias\", \"bert.bert.encoder.layer.10.output.dense.weight\", \"bert.bert.encoder.layer.10.output.dense.bias\", \"bert.bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.bert.encoder.layer.11.attention.self.query.weight\", \"bert.bert.encoder.layer.11.attention.self.query.bias\", \"bert.bert.encoder.layer.11.attention.self.key.weight\", \"bert.bert.encoder.layer.11.attention.self.key.bias\", \"bert.bert.encoder.layer.11.attention.self.value.weight\", \"bert.bert.encoder.layer.11.attention.self.value.bias\", \"bert.bert.encoder.layer.11.attention.output.dense.weight\", \"bert.bert.encoder.layer.11.attention.output.dense.bias\", \"bert.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.11.intermediate.dense.weight\", \"bert.bert.encoder.layer.11.intermediate.dense.bias\", \"bert.bert.encoder.layer.11.output.dense.weight\", \"bert.bert.encoder.layer.11.output.dense.bias\", \"bert.bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.bert.encoder.layer.11.output.LayerNorm.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoints/modelx_URLBERT_80.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path, map_location\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[0;32m---> 55\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     58\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.9/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\". \n\tUnexpected key(s) in state_dict: \"bert.bert.embeddings.word_embeddings.weight\", \"bert.bert.embeddings.position_embeddings.weight\", \"bert.bert.embeddings.token_type_embeddings.weight\", \"bert.bert.embeddings.LayerNorm.weight\", \"bert.bert.embeddings.LayerNorm.bias\", \"bert.bert.encoder.layer.0.attention.self.query.weight\", \"bert.bert.encoder.layer.0.attention.self.query.bias\", \"bert.bert.encoder.layer.0.attention.self.key.weight\", \"bert.bert.encoder.layer.0.attention.self.key.bias\", \"bert.bert.encoder.layer.0.attention.self.value.weight\", \"bert.bert.encoder.layer.0.attention.self.value.bias\", \"bert.bert.encoder.layer.0.attention.output.dense.weight\", \"bert.bert.encoder.layer.0.attention.output.dense.bias\", \"bert.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.0.intermediate.dense.weight\", \"bert.bert.encoder.layer.0.intermediate.dense.bias\", \"bert.bert.encoder.layer.0.output.dense.weight\", \"bert.bert.encoder.layer.0.output.dense.bias\", \"bert.bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.bert.encoder.layer.1.attention.self.query.weight\", \"bert.bert.encoder.layer.1.attention.self.query.bias\", \"bert.bert.encoder.layer.1.attention.self.key.weight\", \"bert.bert.encoder.layer.1.attention.self.key.bias\", \"bert.bert.encoder.layer.1.attention.self.value.weight\", \"bert.bert.encoder.layer.1.attention.self.value.bias\", \"bert.bert.encoder.layer.1.attention.output.dense.weight\", \"bert.bert.encoder.layer.1.attention.output.dense.bias\", \"bert.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.1.intermediate.dense.weight\", \"bert.bert.encoder.layer.1.intermediate.dense.bias\", \"bert.bert.encoder.layer.1.output.dense.weight\", \"bert.bert.encoder.layer.1.output.dense.bias\", \"bert.bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.bert.encoder.layer.2.attention.self.query.weight\", \"bert.bert.encoder.layer.2.attention.self.query.bias\", \"bert.bert.encoder.layer.2.attention.self.key.weight\", \"bert.bert.encoder.layer.2.attention.self.key.bias\", \"bert.bert.encoder.layer.2.attention.self.value.weight\", \"bert.bert.encoder.layer.2.attention.self.value.bias\", \"bert.bert.encoder.layer.2.attention.output.dense.weight\", \"bert.bert.encoder.layer.2.attention.output.dense.bias\", \"bert.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.2.intermediate.dense.weight\", \"bert.bert.encoder.layer.2.intermediate.dense.bias\", \"bert.bert.encoder.layer.2.output.dense.weight\", \"bert.bert.encoder.layer.2.output.dense.bias\", \"bert.bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.bert.encoder.layer.3.attention.self.query.weight\", \"bert.bert.encoder.layer.3.attention.self.query.bias\", \"bert.bert.encoder.layer.3.attention.self.key.weight\", \"bert.bert.encoder.layer.3.attention.self.key.bias\", \"bert.bert.encoder.layer.3.attention.self.value.weight\", \"bert.bert.encoder.layer.3.attention.self.value.bias\", \"bert.bert.encoder.layer.3.attention.output.dense.weight\", \"bert.bert.encoder.layer.3.attention.output.dense.bias\", \"bert.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.3.intermediate.dense.weight\", \"bert.bert.encoder.layer.3.intermediate.dense.bias\", \"bert.bert.encoder.layer.3.output.dense.weight\", \"bert.bert.encoder.layer.3.output.dense.bias\", \"bert.bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.bert.encoder.layer.4.attention.self.query.weight\", \"bert.bert.encoder.layer.4.attention.self.query.bias\", \"bert.bert.encoder.layer.4.attention.self.key.weight\", \"bert.bert.encoder.layer.4.attention.self.key.bias\", \"bert.bert.encoder.layer.4.attention.self.value.weight\", \"bert.bert.encoder.layer.4.attention.self.value.bias\", \"bert.bert.encoder.layer.4.attention.output.dense.weight\", \"bert.bert.encoder.layer.4.attention.output.dense.bias\", \"bert.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.4.intermediate.dense.weight\", \"bert.bert.encoder.layer.4.intermediate.dense.bias\", \"bert.bert.encoder.layer.4.output.dense.weight\", \"bert.bert.encoder.layer.4.output.dense.bias\", \"bert.bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.bert.encoder.layer.5.attention.self.query.weight\", \"bert.bert.encoder.layer.5.attention.self.query.bias\", \"bert.bert.encoder.layer.5.attention.self.key.weight\", \"bert.bert.encoder.layer.5.attention.self.key.bias\", \"bert.bert.encoder.layer.5.attention.self.value.weight\", \"bert.bert.encoder.layer.5.attention.self.value.bias\", \"bert.bert.encoder.layer.5.attention.output.dense.weight\", \"bert.bert.encoder.layer.5.attention.output.dense.bias\", \"bert.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.5.intermediate.dense.weight\", \"bert.bert.encoder.layer.5.intermediate.dense.bias\", \"bert.bert.encoder.layer.5.output.dense.weight\", \"bert.bert.encoder.layer.5.output.dense.bias\", \"bert.bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.bert.encoder.layer.6.attention.self.query.weight\", \"bert.bert.encoder.layer.6.attention.self.query.bias\", \"bert.bert.encoder.layer.6.attention.self.key.weight\", \"bert.bert.encoder.layer.6.attention.self.key.bias\", \"bert.bert.encoder.layer.6.attention.self.value.weight\", \"bert.bert.encoder.layer.6.attention.self.value.bias\", \"bert.bert.encoder.layer.6.attention.output.dense.weight\", \"bert.bert.encoder.layer.6.attention.output.dense.bias\", \"bert.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.6.intermediate.dense.weight\", \"bert.bert.encoder.layer.6.intermediate.dense.bias\", \"bert.bert.encoder.layer.6.output.dense.weight\", \"bert.bert.encoder.layer.6.output.dense.bias\", \"bert.bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.bert.encoder.layer.7.attention.self.query.weight\", \"bert.bert.encoder.layer.7.attention.self.query.bias\", \"bert.bert.encoder.layer.7.attention.self.key.weight\", \"bert.bert.encoder.layer.7.attention.self.key.bias\", \"bert.bert.encoder.layer.7.attention.self.value.weight\", \"bert.bert.encoder.layer.7.attention.self.value.bias\", \"bert.bert.encoder.layer.7.attention.output.dense.weight\", \"bert.bert.encoder.layer.7.attention.output.dense.bias\", \"bert.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.7.intermediate.dense.weight\", \"bert.bert.encoder.layer.7.intermediate.dense.bias\", \"bert.bert.encoder.layer.7.output.dense.weight\", \"bert.bert.encoder.layer.7.output.dense.bias\", \"bert.bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.bert.encoder.layer.8.attention.self.query.weight\", \"bert.bert.encoder.layer.8.attention.self.query.bias\", \"bert.bert.encoder.layer.8.attention.self.key.weight\", \"bert.bert.encoder.layer.8.attention.self.key.bias\", \"bert.bert.encoder.layer.8.attention.self.value.weight\", \"bert.bert.encoder.layer.8.attention.self.value.bias\", \"bert.bert.encoder.layer.8.attention.output.dense.weight\", \"bert.bert.encoder.layer.8.attention.output.dense.bias\", \"bert.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.8.intermediate.dense.weight\", \"bert.bert.encoder.layer.8.intermediate.dense.bias\", \"bert.bert.encoder.layer.8.output.dense.weight\", \"bert.bert.encoder.layer.8.output.dense.bias\", \"bert.bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.bert.encoder.layer.9.attention.self.query.weight\", \"bert.bert.encoder.layer.9.attention.self.query.bias\", \"bert.bert.encoder.layer.9.attention.self.key.weight\", \"bert.bert.encoder.layer.9.attention.self.key.bias\", \"bert.bert.encoder.layer.9.attention.self.value.weight\", \"bert.bert.encoder.layer.9.attention.self.value.bias\", \"bert.bert.encoder.layer.9.attention.output.dense.weight\", \"bert.bert.encoder.layer.9.attention.output.dense.bias\", \"bert.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.9.intermediate.dense.weight\", \"bert.bert.encoder.layer.9.intermediate.dense.bias\", \"bert.bert.encoder.layer.9.output.dense.weight\", \"bert.bert.encoder.layer.9.output.dense.bias\", \"bert.bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.bert.encoder.layer.10.attention.self.query.weight\", \"bert.bert.encoder.layer.10.attention.self.query.bias\", \"bert.bert.encoder.layer.10.attention.self.key.weight\", \"bert.bert.encoder.layer.10.attention.self.key.bias\", \"bert.bert.encoder.layer.10.attention.self.value.weight\", \"bert.bert.encoder.layer.10.attention.self.value.bias\", \"bert.bert.encoder.layer.10.attention.output.dense.weight\", \"bert.bert.encoder.layer.10.attention.output.dense.bias\", \"bert.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.10.intermediate.dense.weight\", \"bert.bert.encoder.layer.10.intermediate.dense.bias\", \"bert.bert.encoder.layer.10.output.dense.weight\", \"bert.bert.encoder.layer.10.output.dense.bias\", \"bert.bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.bert.encoder.layer.11.attention.self.query.weight\", \"bert.bert.encoder.layer.11.attention.self.query.bias\", \"bert.bert.encoder.layer.11.attention.self.key.weight\", \"bert.bert.encoder.layer.11.attention.self.key.bias\", \"bert.bert.encoder.layer.11.attention.self.value.weight\", \"bert.bert.encoder.layer.11.attention.self.value.bias\", \"bert.bert.encoder.layer.11.attention.output.dense.weight\", \"bert.bert.encoder.layer.11.attention.output.dense.bias\", \"bert.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.bert.encoder.layer.11.intermediate.dense.weight\", \"bert.bert.encoder.layer.11.intermediate.dense.bias\", \"bert.bert.encoder.layer.11.output.dense.weight\", \"bert.bert.encoder.layer.11.output.dense.bias\", \"bert.bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.bert.encoder.layer.11.output.LayerNorm.bias\". "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM, BertTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) 토크나이저 로드 경로 수정\n",
    "tokenizer = BertTokenizer(\n",
    "    vocab_file=\"../../bert_tokenizer/vocab.txt\",\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "# 2) AutoConfig.from_pretrained 경로 수정\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"../../bert_config\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    vocab_size=tokenizer.vocab_size\n",
    ")\n",
    "\n",
    "base_bert = AutoModelForMaskedLM.from_config(config)\n",
    "\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, bert, num_labels=2, dropout_prob=0.1, freeze=False):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        if freeze:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.dropout   = nn.Dropout(p=dropout_prob)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        cls_repr = outputs.hidden_states[-1][:, 0, :]\n",
    "        x = self.dropout(cls_repr)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "model = BertForSequenceClassification(\n",
    "    bert=base_bert.bert,\n",
    "    num_labels=2,\n",
    "    dropout_prob=0.1,\n",
    "    freeze=False\n",
    ")\n",
    "\n",
    "# 3) 파인튜닝 체크포인트 경로 수정\n",
    "checkpoint_path = \"./checkpoints/modelx_URLBERT_80.pth\"\n",
    "state_dict = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "def predict_url_probabilities(url: str):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        url,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids      = encoded[\"input_ids\"].to(DEVICE)\n",
    "    token_type_ids = encoded[\"token_type_ids\"].to(DEVICE)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, token_type_ids, attention_mask)\n",
    "        probs  = F.softmax(logits, dim=1)\n",
    "\n",
    "    return {\n",
    "        \"benign (%)\":    round(probs[0, 0].item() * 100, 2),\n",
    "        \"malicious (%)\": round(probs[0, 1].item() * 100, 2)\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_urls = [\n",
    "        \"https://kebhana.com/\",\n",
    "        \"https://sites.google.com/view/update-currently1031/update\"\n",
    "    ]\n",
    "    for url in test_urls:\n",
    "        result = predict_url_probabilities(url)\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\" → 정상(benign) 확률   : {result['benign (%)']}%\")\n",
    "        print(f\" → 악성(malicious) 확률: {result['malicious (%)']}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f25b607c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './checkpoints/modelx_URLBERT_80.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 4) 파인튜닝 체크포인트 로드 (키 이름 재매핑)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoints/modelx_URLBERT_80.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m orig_state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# “bert.bert.xxx” → “bert.xxx” 로 바꿔 주는 단계\u001b[39;00m\n\u001b[1;32m     57\u001b[0m fixed_state \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints/modelx_URLBERT_80.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM, BertTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) 토크나이저 로드\n",
    "tokenizer = BertTokenizer(\n",
    "    vocab_file=\"../../bert_tokenizer/vocab.txt\",\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "# 2) config.json 로 BERT 구조 불러오기\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"../../bert_config\",      # 이 안에 config.json 이 있어야 함\n",
    "    hidden_dropout_prob=0.1,\n",
    "    vocab_size=tokenizer.vocab_size\n",
    ")\n",
    "base_bert = AutoModelForMaskedLM.from_config(config)\n",
    "\n",
    "# 3) 커스텀 분류 모델 정의\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, bert, num_labels=2, dropout_prob=0.1, freeze=False):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        if freeze:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.dropout   = nn.Dropout(p=dropout_prob)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        cls_repr = outputs.hidden_states[-1][:, 0, :]  # [CLS] 토큰 임베딩\n",
    "        x = self.dropout(cls_repr)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "model = BertForSequenceClassification(\n",
    "    bert=base_bert.bert,\n",
    "    num_labels=2,\n",
    "    dropout_prob=0.1,\n",
    "    freeze=False\n",
    ")\n",
    "\n",
    "# 4) 파인튜닝 체크포인트 로드 (키 이름 재매핑)\n",
    "checkpoint_path = \"./checkpoints/modelx_URLBERT_80.pth\"\n",
    "orig_state = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "\n",
    "# “bert.bert.xxx” → “bert.xxx” 로 바꿔 주는 단계\n",
    "fixed_state = {}\n",
    "for k, v in orig_state.items():\n",
    "    if k.startswith(\"bert.bert.\"):\n",
    "        new_k = k.replace(\"bert.bert.\", \"bert.\", 1)\n",
    "    else:\n",
    "        new_k = k\n",
    "    fixed_state[new_k] = v\n",
    "\n",
    "model.load_state_dict(fixed_state)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# 5) 새로운 URL 예측 함수\n",
    "def predict_url_probabilities(url: str):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        url,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids      = encoded[\"input_ids\"].to(DEVICE)\n",
    "    token_type_ids = encoded[\"token_type_ids\"].to(DEVICE)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, token_type_ids, attention_mask)\n",
    "        probs  = F.softmax(logits, dim=1)\n",
    "\n",
    "    return {\n",
    "        \"benign (%)\":    round(probs[0, 0].item() * 100, 2),\n",
    "        \"malicious (%)\": round(probs[0, 1].item() * 100, 2)\n",
    "    }\n",
    "\n",
    "# 6) 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    test_urls = [\n",
    "        \"https://kebhana.com/\",\n",
    "        \"https://sites.google.com/view/update-currently1031/update\"\n",
    "    ]\n",
    "    for url in test_urls:\n",
    "        result = predict_url_probabilities(url)\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\" → 정상(benign) 확률   : {result['benign (%)']}%\")\n",
    "        print(f\" → 악성(malicious) 확률: {result['malicious (%)']}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
